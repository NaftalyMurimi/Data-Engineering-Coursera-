{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5072c65",
   "metadata": {},
   "source": [
    "# Web-scrapping jobs from karatina university website"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c18481f",
   "metadata": {},
   "source": [
    "### NOTE: This project is for learing purposes only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ad80d4",
   "metadata": {},
   "source": [
    "This Prpject aims at scrapping jobs listed at karatina university website. \n",
    "The details to be extracted are job Title, job Grade, No of positions to be filled Positions and Reference Number\n",
    "The data will then be stored in Karu_jobs.csv and karu_jobs.db files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0094d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all neccessary modules\n",
    "import requests\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8d03dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the url to fetch data from\n",
    "url = \"https://karu.ac.ke/past-jobs-karatina-university-page/\"\n",
    "#Declare files to store extracted data\n",
    "karu_jobs = \"karu_jobs.csv\"\n",
    "karu_careers = \"karu_jobs.db\"\n",
    "# Define a dataframe variable to store job Title, job Grade, No of positions to be filled Positions and Reference Number\n",
    "df = pd.DataFrame(columns= [\"Job_Title\", \"Job_Grade\", \"No_Of_Positions\", \"Reference_No\"])\n",
    "count = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "06f5d731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access the contents of the webpage\n",
    "html_page = requests.get(url).text\n",
    "data = BeautifulSoup(html_page, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "944d5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrap the target table data\n",
    "tables = data.find_all('tbody')\n",
    "rows = tables[0].find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5e9868e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate over the content of the table rows and append each row to the dataframe\n",
    "\n",
    "for row in rows:\n",
    "    col = row.find_all('td')\n",
    "    if len(col)!=0:\n",
    "        data_dict = {\"Job_Title\": col[0].contents[1],\n",
    "                     \"Job_Grade\": col[0].contents[2],\n",
    "                     \"No_Of_Positions\": col[0].contents[2],\n",
    "                    \"Reference_No\": col[0].contents[2]}\n",
    "        df1 = pd.DataFrame(data_dict, index=[0])\n",
    "        df = pd.concat([df,df1], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6396d7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Job_Title Job_Grade No_Of_Positions Reference_No\n",
      "0          \\n        \\n              \\n           \\n\n",
      "1          \\n        \\n              \\n           \\n\n",
      "2          \\n        \\n              \\n           \\n\n",
      "3          \\n        \\n              \\n           \\n\n",
      "4          \\n        \\n              \\n           \\n\n",
      "..        ...       ...             ...          ...\n",
      "185    19.           \\n              \\n           \\n\n",
      "186    20.           \\n              \\n           \\n\n",
      "187    21.           \\n              \\n           \\n\n",
      "188    22.           \\n              \\n           \\n\n",
      "189    23.           \\n              \\n           \\n\n",
      "\n",
      "[190 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#View the scrapped data\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1680c192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e40f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcbacc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c7030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1533cab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
